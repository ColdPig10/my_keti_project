# gradio_langgraph_mcp_sse_client.py
import os
from dotenv import load_dotenv
import gradio as gr
import asyncio
from datetime import datetime

from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode, tools_condition
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.runnables import RunnableConfig
from langchain_mcp_adapters.client import MultiServerMCPClient

load_dotenv()

class AgentState(MessagesState):
    pass

async def main():
    # 1. MCP í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
    client = MultiServerMCPClient({
        "mirrorlake": {"url": "", "transport": "sse"},
        "mirrorlake-resource-wrapper": {"url": "", "transport": "sse"},
    })

    # 2. ë„êµ¬ ë¡œë”© ë° LLM ì„¤ì •
    tools = await client.get_tools()
    for tool in tools:
        print(tool, type(tool), "\n")

    llm = ChatOpenAI(temperature=1.0, model='gpt-4o-mini')
    llm_with_tools = llm.bind_tools(tools)
    tool_node = ToolNode(tools)

    # 3. ì—ì´ì „íŠ¸ ì •ì˜
    async def agent(state: AgentState) -> AgentState:
        messages = state["messages"]
        response = await llm_with_tools.ainvoke(messages) # ì‚¬ìš©ìì˜ ëŒ€í™”ë¥¼ ë°›ì•„ LLMì— ì „ì†¡
        return {"messages": [response]} # LLMì´ ëŒ€ë‹µì„ ìƒì„± í›„ ë°˜í™˜

    # 4. LangGraph êµ¬ì„±
    builder = StateGraph(AgentState)
    builder.add_node("agent", agent) #ì‚¬ìš©ìì˜ ë©”ì„¸ì§€ ì²˜ë¦¬(ì§ˆë¬¸ ë¶„ì„, ë‹µë³€ ìƒì„±)
    builder.add_node("tools", tool_node) # í•„ìš”í•œ ë„êµ¬(ì„œë²„) í˜¸ì¶œ

    builder.set_entry_point("agent")
    builder.add_conditional_edges("agent", tools_condition)
    builder.add_edge("tools", "agent")
    builder.add_edge("agent", END)
    graph = builder.compile()

    #ëŒ€í™” ì‹œì‘ -> agentë…¸ë“œ -> (í•„ìš”í•œ ë„êµ¬ ìˆì„ ì‹œ)toolsë…¸ë“œ ì´ë™ -> ì‘ì—… ëë‚˜ë©´ ë‹¤ì‹œ agentë…¸ë“œ -> ì²˜ë¦¬í•  ë‚´ìš© ì—†ìœ¼ë©´ END
    
    # 5. Gradio UI ì •ì˜
    async def query_agent(user_input, chat_history, system_prompt):
        messages = [SystemMessage(content=system_prompt)]
        for i in range(0, len(chat_history), 2):
            messages.append(HumanMessage(content=chat_history[i]["content"]))
            if i + 1 < len(chat_history):
                messages.append(AIMessage(content=chat_history[i + 1]["content"]))
        messages.append(HumanMessage(content=user_input))
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] ì‚¬ìš©ì ì§ˆë¬¸: {user_input}")
        try:
            result = await graph.ainvoke({"messages": messages}, config=RunnableConfig(configurable={"recursion_limit": 50}))
            reply = result["messages"][-1].content
        except Exception as e:
            reply = f"[ì—ëŸ¬] {str(e)}"
            print(f"[{timestamp}] ì—ëŸ¬ ì‘ë‹µ: {reply}")
        else:
            print(f"[{timestamp}] ì±—ë´‡ ì‘ë‹µ: {reply}")

        chat_history.append({"role": "user", "content": user_input})
        chat_history.append({"role": "assistant", "content": reply})
        return chat_history, ""

    #Gradio UI ì‹¤ì œ ë ˆì´ì•„ì›ƒ
    with gr.Blocks() as demo:
        gr.Markdown("# ğŸŒ MirrorLake SSE Chatbot")
        with gr.Row():
            system_prompt = gr.Textbox(
                label="System Prompt",
                lines=20,
                value=(
                    "ë‹¹ì‹ ì€ MirrorLake í”Œë«í¼ì˜ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
                    "MirrorLakeëŠ” ë””ì§€í„¸ íŠ¸ìœˆ(DT), ë””ì§€í„¸ ê°ì²´(DO), ì„¼ì„œ(Sensor)ë¥¼ ì—°í•© êµ¬ì„±í•˜ê³  ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.\n"
                    "MirrorLake í”Œë«í¼ì—ì„œëŠ” ë””ì§€í„¸ íŠ¸ìœˆ(Digital Twin) í•˜ìœ„ì— ì„¼ì„œë¥¼ ë“±ë¡í•˜ë©°,\n"
                    "ë“±ë¡ëœ ì„¼ì„œ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì¡°í•©í•˜ì—¬ ë””ì§€í„¸ ê°ì²´(Digital Object)ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                    "ì´ë•Œ ë””ì§€í„¸ ê°ì²´ëŠ” ì—°ê²°ëœ ì„¼ì„œë“¤ì˜ ë°ì´í„°ë¥¼ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n\n"
                    "[ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬]\n"
                    "- list_digital_twins(): ë“±ë¡ëœ ëª¨ë“  DT ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n"
                    "- list_all_digital_objects(): ë“±ë¡ëœ ëª¨ë“  DO ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n"
                    "- list_all_sensors(): ë“±ë¡ëœ ëª¨ë“  ì„¼ì„œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n"
                    "- get_sensor_data(dt_id, sensor_id): íŠ¹ì • ì„¼ì„œì˜ ìµœì‹  ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n"
                    "- get_do_data(dt_id, do_id): íŠ¹ì • ë””ì§€í„¸ ê°ì²´(DO)ì˜ ìµœì‹  ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n"
                    "- list_all_simulations(): ë“±ë¡ëœ ëª¨ë“  ì‹œë®¬ë ˆì´ì…˜(simulation) ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n"
                    "- list_all_subscriptions(): ë“±ë¡ëœ ëª¨ë“  êµ¬ë…(subscription)  ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n"
                    "- get_simulation_data(dt_id, sim_id): íŠ¹ì • ì‹œë®¬ë ˆì´ì…˜(simulation) ìµœì‹  ê²°ê³¼ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤\n"
                    "[ë„êµ¬ ì‚¬ìš© ìš°ì„ ìˆœìœ„ ë° ë‹µë³€ ì¶œì²˜ ì§€ì¹¨]\n"
                    "- ì§ˆë¬¸ì´ ì£¼ì°¨ì¥, ì£¼ì°¨ì¥ë²• ë“±ê³¼ ê´€ë ¨ë˜ì–´ ìˆë‹¤ë©´, ë°˜ë“œì‹œ self_rag_toolì„ ë¨¼ì € ì‚¬ìš©í•˜ì„¸ìš”.\n"
                    "- self_rag_tool ë‹µë³€ì´ ì¶©ë¶„í•˜ì§€ ì•Šê±°ë‚˜, PDFì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í•˜ë©´ ê·¸ë•Œë§Œ GPTì˜ ìì²´ ì§€ì‹ìœ¼ë¡œ ë³´ì™„í•˜ì„¸ìš”.\n"
                    "- ë‹µë³€ë§ˆë‹¤ ì¶œì²˜(ì˜ˆ: PDF ê¸°ë°˜, GPT ê¸°ë°˜, ë‘˜ ë‹¤ ë“±)ë¥¼ ë°˜ë“œì‹œ í‘œì‹œí•˜ì„¸ìš”.\n"
                    "- ì˜ˆì‹œ: 'ì•„ë˜ ë‹µë³€ì€ PDF ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.'\n"
                    "        'ì•„ë˜ ë‹µë³€ì€ PDFì˜ ì¼ë¶€ ë‚´ìš©ê³¼ GPTì˜ ì¼ë°˜ ì§€ì‹ì„ í•¨ê»˜ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.'\n"
                    "        'PDFì— ì •ë³´ê°€ ì—†ì–´ GPT ìì²´ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.'\n"
                    "\n"
                    " ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì— ì ì ˆíˆ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:\n"                    
                    "- 'ëª¨ë“  DT ì •ë³´ë¥¼ ì•Œë ¤ì¤˜'\n"                
                    "- 'ëª¨ë“  DO ì •ë³´ë¥¼ ì•Œë ¤ì¤˜'\n"                
                    "- 'ëª¨ë“  ì„¼ì„œ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜'\n"
                    "- 'ì„¼ì„œ S001ì˜ ìµœê·¼ ë°ì´í„°ë¥¼ ì•Œë ¤ì¤˜'\n"
                    "- 'KR-02 íŠ¸ìœˆì˜ DO do-line-01 ìƒíƒœ ì•Œë ¤ì¤˜'\n"
                    "- 'KR-02ì˜ S_Temp_02 ì„¼ì„œê°’ ë³´ì—¬ì¤˜'"
                    "- í•œì‹œê°„ ì „ë¶€í„° ì§€ê¸ˆê¹Œì§€ì˜ S_cotlab_TpHm_010 ì„¼ì„œë°ì´í„°ë¥¼ ì¡°íšŒí•´ì¤˜"
                    "- SIM-water-predictì˜ 2025-02-18 8ì‹œ ë¶€í„° 30ë¶„ ë™ì•ˆì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•´ì¤˜"
                ),
            )
        chatbot = gr.Chatbot(height=500, type="messages")
        user_input = gr.Textbox(show_label=False, placeholder="MirrorLake ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
        send_btn = gr.Button("ì „ì†¡")
        state = gr.State([])

        send_btn.click(query_agent, inputs=[user_input, state, system_prompt], outputs=[chatbot, user_input])
        user_input.submit(query_agent, inputs=[user_input, state, system_prompt], outputs=[chatbot, user_input])

    #Gradio ì„œë²„ ì‹¤í–‰
    demo.launch(server_name="0.0.0.0", server_port=7860)

if __name__ == "__main__":
    asyncio.run(main())

#ë…¼ë¦¬ íë¦„
# MCP ì„œë²„(ì›ë³¸, ìš”ì•½)ì—ì„œ Tool ì •ë³´ë¥¼ ê°€ì ¸ì™€ ì¤€ë¹„

# LLM + Tool ì¡°í•©ìœ¼ë¡œ ëŒ€í™” Agentì™€ Tool ë…¸ë“œ ì—°ê²°

# LangGraphë¡œ ì „ì²´ ëŒ€í™”íë¦„/Tool í˜¸ì¶œ/ì¬ê·€ ì²˜ë¦¬ ë“± ì›Œí¬í”Œë¡œìš° ì™„ì„±

# Gradioë¡œ ì›¹ì±—ë´‡ UI ìƒì„±, ì‚¬ìš©ìê°€ ì§ˆë¬¸/ëŒ€í™” ê°€ëŠ¥

# LLMì´ ìì—°ì–´ ì§ˆë¬¸ì„ ì´í•´í•´ì„œ, í•„ìš”í•œ Tool(MCP ì„œë²„ API)ì„ ìë™ í˜¸ì¶œ, ê²°ê³¼ë¥¼ ì½ê¸° ì‰½ê²Œ ëŒ€ë‹µ

# ëª¨ë“  ì²˜ë¦¬ê°€ ë¹„ë™ê¸°ë¡œ ë¹ ë¥´ê²Œ ìˆ˜í–‰

print("Working Dir:", os.getcwd())
print("Persist DB exists?:", os.path.exists('./pdf_test_chroma_db'))